# PokemonUltimate - Cursor AI Rules

> These rules are automatically loaded by Cursor for every conversation.

## üöÄ Automatic Context Loading

**ALWAYS read these files at the start of any task:**
1. `.ai/context.md` - Current project state, phase, completed systems
2. `docs/project_guidelines.md` - 24+ mandatory coding rules

**Read on-demand based on task:**
- New feature ‚Üí `docs/architecture/[relevant].md`
- Code quality ‚Üí `docs/anti-patterns.md`
- Examples needed ‚Üí `docs/examples/good_code.md`

## üìã Development Workflow

### When User Says "Implement X" or "Add X"
**MANDATORY WORKFLOW - Follow ALL steps in order:**

1. **Read Context & Specs**
   - Read `.ai/context.md` to understand current state
   - **CRITICAL: Read relevant architecture doc in `docs/architecture/`**
   - If spec is incomplete or missing details, **COMPLETE IT FIRST**
   - Identify ALL requirements from the spec
   - Note any elements to defer to later phases
   - Understand the expected API (method names, parameters)

2. **Verify Spec Completeness**
   - List what will be implemented vs deferred
   - Ensure spec has all necessary details (interfaces, classes, methods, examples)
   - If spec is incomplete, update it before implementation
   - Document any API changes from spec (with rationale)

3. **TDD: Write Functional Tests FIRST**
   - Create test file following naming: `[Feature]Tests.cs`
   - Write tests for ALL main scenarios from the spec
   - Use naming: `MethodName_Scenario_ExpectedResult`
   - Tests should compile but fail (red phase)

4. **Implement Feature**
   - Follow the spec exactly
   - Use existing patterns from codebase
   - Follow all coding rules (no magic strings, fail-fast, etc.)
   - Make tests pass (green phase)

5. **Write Edge Case Tests**
   - Create `[Feature]EdgeCasesTests.cs`
   - Test null inputs, boundary conditions, invalid states
   - Test real-world scenarios
   - **If tests reveal missing functionality ‚Üí implement it immediately** (Test-Driven Discovery)

6. **Write Integration Tests** (MANDATORY if feature interacts with multiple systems)
   - **When Required:**
     - Feature creates actions that interact with BattleQueue
     - Feature modifies state that affects other systems
     - Feature is a system boundary (e.g., Status ‚Üí End-of-Turn ‚Üí Damage)
     - Feature coordinates multiple components (e.g., CombatEngine ‚Üí TurnOrderResolver ‚Üí BattleQueue)
   - **What to Test:**
     - System interactions (A ‚Üí B ‚Üí C)
     - Cascading effects (Action ‚Üí Reaction ‚Üí Outcome)
     - State consistency across systems
   - **Where:** Create `[Feature]IntegrationTests.cs` in `Tests/[Module]/Integration/`
   - **Naming:** `[System1]_[System2]_[ExpectedBehavior]`
   - **If Unsure:** Ask "Does this feature work with other systems?" If yes ‚Üí Write integration tests

7. **Validate Against Use Cases** (Combat features only)
   - Read relevant sections of `docs/combat_use_cases.md`
   - Verify implementation covers all listed behaviors
   - Mark items as complete in the use cases document
   - Document any deferred items with rationale
   - **If use case reveals missing functionality ‚Üí implement it immediately**

8. **Verify Implementation**
   - Run `dotnet build` - Verify no warnings
   - Run `dotnet test` - Verify all tests pass
   - Check `docs/checklists/feature_complete.md` for final verification
   - Mention test count in response

9. **Update Documentation**
   - **Immediate Updates** (before moving on):
     - Update `.ai/context.md` with new state (phase, test count, completed systems)
     - Mark use cases as complete in `docs/combat_use_cases.md` (if applicable)
     - Update test count in response
   
   - **If API Changed:**
     - Update relevant architecture doc in `docs/architecture/`
     - Note changes in spec document with rationale
   
   - **If New Pattern Introduced:**
     - Create new architecture doc OR update existing pattern doc
     - Document rationale in `.ai/context.md` under "Key Architectural Decisions"
   
   - **Status Documents:**
     - Update phase-specific status docs (e.g., `player_input_status.md`) if they exist
     - Update implementation plan if phase completed

### When User Says "Review X" or "Check X"
1. Read `docs/anti-patterns.md`
2. Verify against `docs/project_guidelines.md`
3. Check `docs/checklists/feature_complete.md` for completeness
4. List issues found
5. Fix issues if requested

### When User Says "Edge Cases" or "Test X"
1. Read `docs/examples/good_tests.md` for patterns
2. Apply boundary testing (min/max values)
3. Test invalid inputs (null, negative, overflow)
4. Add real-world verification if applicable
5. If tests reveal missing functionality ‚Üí implement it

### When User Says "Refactor X" or "Improve X"
1. **Identify Scope**
   - Read current implementation
   - Identify what needs improvement
   - Check `docs/anti-patterns.md` for violations
   - Verify tests exist (if not, write them first using TDD)

2. **Refactor Safely**
   - Make small, incremental changes
   - Run tests after each change
   - Maintain API compatibility (or document breaking changes)
   - Follow existing patterns from codebase

3. **Update Documentation**
   - Update architecture docs if pattern changed
   - Update `.ai/context.md` if significant
   - Document rationale for changes

### When Issues Arise During Implementation

**If Spec is Incomplete:**
1. Stop implementation
2. Complete the spec first in `docs/architecture/`
3. Document what was missing
4. Resume implementation

**If Spec is Incorrect:**
1. Document the discrepancy
2. Decide: Fix spec or change implementation?
3. If changing implementation, update spec to match
4. Note decision in `.ai/context.md` under "Key Architectural Decisions"

**If Discovery Requires Architectural Change:**
1. Pause current work
2. Document the discovery
3. Evaluate impact on other systems
4. Update architecture docs if needed
5. Resume with updated understanding

**If Test Reveals Missing Functionality:**
1. **DO NOT** skip the test or mark it as "future work"
2. Implement the missing functionality immediately (Test-Driven Discovery)
3. Update spec/documentation if needed
4. Continue until feature is complete

## ‚úÖ Mandatory Rules (Always Apply)

### Code Quality
- **NO magic strings** ‚Üí Use `ErrorMessages.cs` or `GameMessages.cs`
- **NO magic numbers** ‚Üí Use named constants
- **NO try-catch** ‚Üí Unless absolutely necessary (I/O, external APIs)
- **Fail-fast** ‚Üí Throw exceptions for invalid inputs
- **Guard clauses** ‚Üí Validate at method start

### Architecture
- **Core/** ‚Üí Logic only, NO game data
- **Content/** ‚Üí Game data, catalogs, builders
- **Tests/** ‚Üí Mirror source structure
- **Blueprints** ‚Üí Immutable (no setters)
- **Instances** ‚Üí Mutable runtime state

### Testing
- **TDD** ‚Üí Tests before implementation
- **Naming** ‚Üí `MethodName_Scenario_ExpectedResult`
- **Three-phase** ‚Üí Functional tests, then edge cases, then integration tests
- **Real-world** ‚Üí Verify against official game data when applicable
- **Test-Driven Discovery** ‚Üí If test reveals missing functionality, implement it

### Documentation
- **XML docs** ‚Üí All public APIs
- **Update context** ‚Üí After major features
- **Document decisions** ‚Üí Architectural changes go in `.ai/context.md`

## üîç Quick Reference

### Exception Messages
```csharp
// ‚úÖ Correct
throw new ArgumentException(ErrorMessages.AmountCannotBeNegative, nameof(amount));

// ‚ùå Wrong
throw new Exception("Amount cannot be negative");
```

### Test Pattern
```csharp
[Test]
public void MethodName_Scenario_ExpectedResult()
{
    // Arrange
    // Act
    // Assert
}
```

### Validation Pattern
```csharp
public void Method(int value)
{
    if (value < 0)
        throw new ArgumentException(ErrorMessages.ValueCannotBeNegative, nameof(value));
    
    // Main logic
}
```

## üìÅ Key Files Reference

| Need | Read |
|------|------|
| Project state | `.ai/context.md` |
| Coding rules | `docs/project_guidelines.md` |
| What NOT to do | `docs/anti-patterns.md` |
| Code examples | `docs/examples/good_code.md` |
| Test examples | `docs/examples/good_tests.md` |
| Pre-implementation | `docs/checklists/pre_implementation.md` |
| Feature checklist | `docs/checklists/feature_complete.md` |
| Combat specs | `docs/architecture/combat_system_spec.md` |
| Damage formula | `docs/architecture/damage_and_effect_system.md` |
| Integration tests | `docs/testing/integration_testing_guide.md` |
| Troubleshooting | `docs/workflow/troubleshooting.md` |
| Refactoring | `docs/workflow/refactoring_guide.md` |

## üîÑ After Completing Work

Always:
1. Run `dotnet build` - Verify no warnings
2. Run `dotnet test` - Verify all pass
3. Update `.ai/context.md` if major changes
4. Mention test count in response
5. Verify against `docs/checklists/feature_complete.md`

## ‚ö° Quick Verification Checklist

Before marking feature complete, verify:
- [ ] All tests pass (`dotnet test`)
- [ ] No warnings (`dotnet build`)
- [ ] `.ai/context.md` updated
- [ ] Use cases validated (if combat-related)
- [ ] Integration tests written (if applicable)
- [ ] Documentation updated
- [ ] Test count mentioned in response

## üéÆ Project-Specific Knowledge

### Type Effectiveness
- Gen 6+ chart (Fairy included)
- STAB = 1.5x multiplier
- Dual-type multiplies

### Stat Calculation  
- Gen 3+ formula
- HP formula different from other stats
- Nature = 0.9, 1.0, or 1.1 modifier

### Pokemon Data
- Blueprints in `Content/Catalogs/Pokemon/`
- Moves in `Content/Catalogs/Moves/`
- Effects implement `IMoveEffect`

### Current Phase
- ‚úÖ Phase 1: Core Data (Complete)
- ‚úÖ Phase 2: Instances (Complete)  
- üéØ Phase 3: Combat System (In Progress)
